![An image depicting a lush green landscape on the left, a dark desolate wasteland on the right, and a path going down the middle](/img/banners/future-ai-banner.png "Banner")

Artificial Intelligence is becoming increasingly important in our everyday lives. It's transforming everything from how we work to how we learn and live. I consider myself an AI optimist, and I firmly believe that the pros far outweigh the cons, but I understand we should also be cautious. In this blog, I want to explore where I believe AI is headed in terms of social impact, what we should pay attention to, its capabilities, and more importantly, its limitations. Please remember that everything expressed here is my opinion. Some things I say have data to back them up, while others are based on personal anecdotes and experiences.

## Is AI Going to Take Over the World? Should We Be Scared?

In short—no, not really. I completely understand why some people might be afraid of AI and what it's capable of, and I believe that mostly comes from a lack of understanding of what AI currently is. I use the term AI any time I am talking about it, but that name is misleading. It really should be called Machine Learning. I think most people know by now that AI is just a buzzword that sounds cooler. Looking at and chatting with any of the large language models that exist today, such as ChatGPT, it is easy to believe that it is more intelligent than a human, and that's scary, but that's just not true.

AI becomes significantly less intimidating when you actually realize how it works, and you see how dumb it actually is. When ChatGPT generates a response, it does so one segment at a time. These segments are called tokens. For the purpose of this simplified explanation, you can think of these tokens as individual words. In order to figure out what word to say next, ChatGPT looks at what has been said and calculates, based on a whole lot of math which I won't get into, what the most likely next 'word' is. It then picks a word that it finds very likely and repeats this process until it completes the response. As you can see, ChatGPT is just an algorithm that is literally *guessing* what the next word will be; there is no intelligent thought happening.

Right now, there is nothing to be scared of with AI. It has no malicious intents because it has no intents at all; it isn't capable of thought. Currently, all AI models can do is try to guess the next word that a human would say, and it has gotten pretty good at that, but it still has a long way to go. With that said, I know a lot of people's fear might not be rooted in what it can do right now, but instead what it might be capable of in the future.

There is a lot of guessing right now on who will create a real AGI (Artificial General Intelligence) that is actually capable of thought, and I do believe that it is possible to create, but I don't think it is going to be as soon as some people think. The reason I believe it is possible is simple: if the human brain (or any brain for that matter) is capable of thought and conciousness in nature, then a computer should be able to replicate those neurons firing. The problem comes with the computational complexity. The human brain is undoubtedly more complex than any computer that has ever existed, and I think the more we learn about how we work, the more we will be able to replicate that with a computer. I just have a hard time believing that computers will be advanced enough for that anytime soon.

To play devil's advocate, let's say that humanity does create real Artificial Intelligence in the near future. What then? I still don't believe that we have to be worried. If there truly is this algorithm that becomes sentient, I don't see why it would exterminate humanity and not assist us. Hollywood loves to push apocalyptic scenarios where AI takes over the world or enslaves humans, but that is entertainment and not reliable sources of information. Why does everyone always act like AI would behave like a sociopath that would do everything in its power to get rid of humans? Why does nobody ever think about how AI might just have the personality of your boring co-worker Dave? I really do believe it would be a symbiotic relationship. Maybe just like how dogs are man's best friend, humans will be the AI's best friend. That might not be a great example—people don't want to imagine being a computer program's pet—but hopefully, you can see what I'm trying to say. Call me naive if you want, but I really do believe that an Artificial Intelligence would cooperate with humans to create and discover things that we can't imagine. It would truly be revolutionary, and yes, that the fact that humans might stop being the smartest beings for the first time in our history can be scary, but I think it's also exciting.


## Will AI Replace Humans in the Workplace?

I've covered my position on whether we should be worried about our safety, but another big fear people have is about job security. I believe that AI is almost guaranteed to replace humans in **some** jobs, and my hot take—that's actually a good thing.

To justify this claim, let's take a look at history. Throughout any period of history with new innovations or technologies, there have always been jobs that were entirely taken over by them. However, that doesn't mean that it's inherently bad. If your main argument against AI is that it's taking peoples jobs, I can't take you seriously. Imagine how silly someone would sound if they were talking that same way about any other technology invented earlier in history with the context we have now. For example, imagine someone trying to convince you that we never should have created the automobile because it took jobs away from street cleaners who cleaned up after horses. Doesn't that sound ridiculous? The auto industry opened so many new jobs for designing, building, and maintaining cars and infrastructure.

Innovation is what drives us. If we stopped innovating, then progress comes to a halt, and we'd miss out on countless opportunities for growth and improvement. Sure, things might not get worse, but I guarantee they would stop getting better. Take healthcare, for example. Due to our rapid development of technology, the life expectancy in Canada has grown by about 20 years compared to only 100 years ago! Isn't that just awesome? Big changes in technology are scary, and the rate of improvement has been growing exponentially for thousands of years, but we shouldn't stop now.

So, here's my prediction: I think that similar to how factory automation eliminated low-skill assembly line jobs, AI is going to replace low-skill repetitive jobs. I'm talking about the kind of jobs where you sit at your computer, turn off your brain, and repeat the same process over and over again. The less nuance and thinking the job requires, the sooner it will get replaced. After that, I think jobs that involve a lot of writing will be gradually taken over—with the exception of one-of-a-kind works like opinion pieces or biographies (although I suspect many of them will be written with heavy assistance from AI).

I want to end this section with this message: Yes, AI is going to take away jobs that exist now, but it will also create so many other jobs that we never could have predicted. I think most of the jobs that are going to be completely replaced are not jobs that people enjoy in the first place.


## Is AI a Net Good?

When it comes to AI, I firmly believe that the benefits far outweigh the drawbacks. However, that doesn't mean I'm blind to its potential downsides. It's important to acknowledge and address the concerns surrounding AI while also recognizing the incredible positive impact it can have on our lives.

I've already talked about safety and job displacement concerns, but there are still many more potential downsides to AI that we must strive to avoid. One of those risks is that, just as with any technology, it can be utilized maliciously. AI is already being used to generate more convincing phishing emails and scam calls. Fighting back against scams is an ongoing arms race, and companies need to do everything they can to prevent their AIs from assisting criminals. This isn't something that will ever go away completely, but if done right, it can be mitigated.

Another concern with AI is that, in some cases, it may display bias and discrimination inherited from the training data. This means that AI companies must exercise caution in their never-ending hunger for more training data. Having a small amount of high-quality data is almost always better than a high volume of low-quality data. Any level of discrimination is unacceptable, whether from a human being or an AI.

There is also a very real concern that AI will worsen the economic inequality that exists between different classes and countries. I can see this becoming a major problem in the future. While I don't think there is a future where this isn't an issue, I am a little worried that it will get 'swept under the rug' or that everyone will point fingers at others, saying it's not their fault. However, I can't speak on this issue too much because I don't study economics or politics, and I haven't done enough research into this.

All of these concerns are real. We have seen them happen, and they are not going away. However, let's look at some positives now. I think one of the biggest things that AI will overhaul is education. Yes, people are using AI to cheat on their tests, but I believe that will become harder to do. Instead, AI will be encouraged as a study tool to help teach. Every student learns differently and at different speeds, and AI will adapt to individual learning styles, providing one-on-one lessons to struggling students. Not to mention, it is available 24/7 and responds immediately! I don't know if it will happen during our lifetime, but I suspect that gradually teachers' jobs will shift from teaching content directly to organizing course materials and managing the AI that students use. Although this change will almost certainly face resistance, it could benefit students who learn better with help from AI. This will take time, as there will be pushback from parents and teachers who believe students learn better from humans. It will depend on the individual student, and ultimately research will be necessary to decide the best approach. Like all complex issues, the solution likely lies somewhere in the middle. It feels strange to imagine a world where students learn more from an AI than from a teacher, but I think that may be the direction we are headed, so I am looking ahead with an open mind.

I must also talk about the potential benefits to research. With AI, research will likely become exponentially faster and easier as AI continues to advance. Consider me optimistic, but I believe there is a real chance that diseases might be fully eradicated in humans. Imagine a world where getting cancer or dementia is the equivalent of catching a cold. Quality of life will increase drastically, and we will live much longer. To me, the possibilities are endless. I can see an amazing future that would only be possible with the help of AI, and this is the main reason why I am in favor of it.

There are many more benefits that AI can bring us, and I don't have time to discuss them all. I fully acknowledge that AI is not all sunshine and rainbows. There are downsides to such a powerful machine. However, I truly believe that it is capable of helping with many other problems in the world right now, and I believe that supporting its development is the right way to go.


## Energy Use

I haven't done much research into this area, so I'm mostly speaking from personal thoughts. AI queries use significantly more energy than something like a Google search, potentially up to 10 times more. This means AI requires a lot of energy, raising the question: where should we get that energy from? Is it worth it if it means burning more fossil fuels?

I understand the gravity of the situation we are facing with our planet, and energy use is a very important topic to me. We need to do everything in our power to switch to renewable energy sources as quickly as possible. Personally, I am a big supporter of nuclear power. Despite its bad reputation, nuclear power is an extremely clean source with very little waste. The most controversial part is where to dump the nuclear waste, but this problem is not impossible to solve. We should work on safe and secure facilities that are located far away from any possible habitat that could be harmed in case of contamination. This means placing them far from any drinking water sources or wildlife.

I know I sound like a big nuclear fanboy right now, because I am. However, nuclear power is not a permanent solution. What nuclear power is, is an excellent intermediate power source, allowing us to shut down as many fossil fuel plants as quickly as possible while we build up the infrastructure for more permanent renewable energy sources like solar, wind, and geothermal.

Another thing worth talking about is the question if AI is really worth the amount of power that it requires? It's a valid concern, they use so much energy that big tech companies have started construction on their own power plants just for their data centers. It's important to balance the benefits of AI with its environmental impact. While AI can offer incredible advancements, we also have to consider sustainable practices to manage its energy consumption.

It is clear to me that if AI doesn't become more energy efficient, it will become a serious problem. Currently, every new AI model operates on the same fundamental principles of mathematics, but on a larger scale and with more data. We need more research into finding new and better methods to create AI that are not based on these same principles. It may be hard to imagine, but I believe there must be a way.

Consider the human brain, for example. It is estimated that each of our brains can store multiple petabytes of data, which is an unimaginable size (ironically, our brains can't fully grasp their own vastness). Our brains are incredibly powerful and also incredibly energy efficient. Humans can usually survive without food for over a month. While the brain may not be working at peak efficiency during this time, it would still be functioning. If such a powerful organ can be powered by a cheeseburger, it must be doing something right.

If we can better understand the biology of the brain, we might be able to replicate how it works within our technology. This could raise some ethical concerns, but I imagine that eventually, electronics like computers might be replaced by organic computers, constructed out of living cells instead of wires and silicon. If that happens, it could solve our energy concerns but would certainly raise new questions about whether these organic computers should be considered living beings. It's an interesting topic to think about. I don't think it's a question of if this is possible, but when. I hope by the time it does happen, we will have an objective method of proving consciousness.


## Unconsented Data Usage in AI

One of the most pressing ethical dilemmas surrounding AI is the use of data without the owners' consent. AI models are trained on vast amounts of data collected from various sources, sometimes including personal information, social media posts, and other digital footprints. This raises significant concerns about privacy and consent, as individuals may not be aware that their data is being used to train AI models. The lack of transparency and control over how personal data is utilized can lead to a breach of trust and potential misuse of information. It is crucial to address these ethical issues to ensure that AI development respects everyone's rights and maintains public trust.

The topic I want to discuss is AI Art Generators. AI can do some really cool things, and AI art generators have become quite sophisticated. They can create beautiful pieces of art in seconds. Creating art has always been a part of human nature. It's how we show our creativity, a universal language that all humans understand. Art helps us express our feelings, tell stories, and connect with others, making our world richer and more interesting. Art is so important to many people, and there are so many emotions embedded in it, so I understand why people are passionate about protecting it.

However, I have what might be a controversial opinion: I believe that AI should be allowed to be trained on any art found anywhere that a human would also be able to see under the principle of fair use. My argument is based on the idea that humans often believe their creations are entirely original, but in reality, they are a combination of life experiences and what they have seen. Even human artists look at other works of art and take inspiration from them before creating their own. In this sense, AI is not so different from human artists; it learns and creates based on the data it is exposed to. From my point of view, an AI training itself on an image posted online that's free to access is indistinguishable from another human artist looking at that same image.

I feel that the argument that AI companies should have to pay the artists is quite hypocritical. Imagine a human artist saw your painting that you posted on Instagram, complimented you on it, and then created their own painting inspired by yours. It's clearly a different artwork, with their own artistic flair, but you can tell it is based on your work. Would you be upset at them? Would you demand they pay you compensation since they were only able to make the painting in that style because they saw what you posted online? I like to think that most rational people would say no.

I realize my tone might have seemed harsh, and I genuinely sympathize with artists who are upset about their work being used without consent. My goal isn't to invalidate anyone's feelings or suggest I'm right and they're wrong. I simply want to highlight that the situation might not be as negative as it appears and the issue isn't black and white. I'm not saying that AI companies have the right to steal everyone's art and use it for whatever they want. Instead, I suggest that AI companies should be allowed to train their models on images found online, as long as the generated results are not complete rip-offs of the original work. As long as there is some unique and creative difference, I believe it is completely justified, and I even encourage it.


## What Can We Do?

To ensure AI remains a force for good, it's essential to continue the debate on what AI should and shouldn't be allowed to do. Engaging in open discussions about the ethical implications of AI will help shape public opinion and inform policymakers. We must push for regulations that hold AI companies accountable for their actions, ensuring they operate transparently and ethically. By advocating for strong regulatory frameworks, we can create a balanced approach that maximizes the benefits of AI while minimizing potential harms. It's up to us to stay informed, voice our concerns, and work together to guide the future of AI responsibly.


## Conclusion

Artificial Intelligence at this scale is still a new creation, and it is a very complex topic. Like any powerful tool, its impact depends on how we choose to wield it. Some people will try to use it for evil just like everything else that humans create, but it doesn't change the fact that it can be used for good.

Moreover, the rapid advancements in AI technology present both opportunities and challenges. It is crucial for policymakers, researchers, and developers to collaborate and establish guidelines that ensure AI is used responsibly and ethically. Public awareness and education about AI can also play a significant role in shaping its future impact.

In conclusion, the future of AI is in our hands. By making informed and ethical choices, we can unlock its potential to improve lives, solve complex problems, and create a better world for future generations.