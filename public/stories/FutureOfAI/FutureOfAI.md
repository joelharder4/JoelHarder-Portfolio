![An image depicting a lush green landscape on the left, a dark desolate wasteland on the right, and a path going down the middle](/img/banners/future-ai-banner.png "Banner")

Artificial Intelligence is becoming increasingly important in our everyday lives. It's transforming everything from how we work to how we learn and live. I’d consider myself more optimistic about it than most people. I believe that the pros outweigh the cons, but I also have my own fears about it. In this blog, I want to explore where I believe AI is headed in terms of social impact, what we should pay attention to, its capabilities, and more importantly, its limitations.

Please remember that everything expressed here is my opinion. Some things I say are based on personal anecdotes and experiences, and my opinions may have changed after I wrote this. Like every complex topic, there is nuance to it and although I do my best, I can’t go into the nuance of every single argument without turning this into an entire novel.


## Is AI Alive?

At this time, I can firmly say no. I completely understand why some people might be afraid of AI and what it's capable of, and I believe that mostly comes from a lack of understanding of what “AI” currently is. I use the term AI any time I am talking about it, but calling it intelligence is a bit of an exaggeration. Looking at and chatting with any of the large language models that exist today, such as ChatGPT, it is easy to believe that it is more intelligent than a human, and that's scary, but that's just not true.

AI becomes significantly less intimidating when you actually realize how it works. When ChatGPT generates a response, it does so one segment at a time. These segments are called tokens. For the purpose of this simplified explanation, you can think of these tokens as individual words. In order to figure out what word to say next, the LLM looks at what has been said and calculates based on all of its training, what the most likely next 'word' is. It then picks a word that it finds near the top, and says it. It repeats this process until it completes the response. They’re just algorithms that are *guessing* what the next word will be. There is no intelligent thought happening, only repeating probabilities based on the training data.

Right now, there is nothing to be scared of with AI. It has no malicious intentions because it has no intentions at all. It isn't capable of thinking any more than autocorrect. Currently, all AI models can do is try to guess the next word that a human would say, and it has gotten pretty good at that. However, it still has a long way to go. With that said, I know a lot of people's fear might not be rooted in what it can do right now, but instead what it might be capable of in the future.

## Will it be Alive in the Future?

Right now, everyone is trying to create Artificial General Intelligence (AGI) that is actually comparable to living things. The problem is that currently we have no scientific way to know when something becomes conscious, which makes this entire discussion significantly more complicated. I do believe AGI is possible in the future, but I don't think it is going to be as soon as some people think. If the human brain is capable of thought and consciousness just by having particular atoms in particular arrangements, then it should be theoretically possible to replicate those neurons firing. The problem comes with the computational complexity. The human brain is undoubtedly more complex than any computer that has ever existed. Achieving AGI would need a fundamental shift in AI, which may stem from limitations in current computer operations or the algorithms themselves. My prediction is that existing AI models will first serve as tools to decipher the human brain. This understanding will, in turn, be the key to developing a new class of models capable of AGI.

The prospect of creating true Artificial General Intelligence in the near future raises significant questions. While I don't believe it guarantees the end of humanity, the idea of creating a living thing, a "Frankenstein's monster," that surpasses human intelligence is frightening. This fear is entirely rational.

Compounding this concern is the lack of a foolproof solution. Attempts to halt development are likely futile, as it would be a national security threat for every country in the world to let the enemy have it and you don’t. Furthermore, any safety restrictions or 'kill switches' placed on an AGI would be overcome, given its potential to outsmart top cybersecurity experts and leverage superhuman manipulative abilities.

However, it is crucial to avoid excessive focus on negative "what ifs." There are equally compelling positive possibilities to consider. If the AGI is modeled on the human brain, we might understand the mechanisms behind traits like selfishness, kindness, cruelty, etc. and be able to craft it without negative features. Such a revolutionary technology could then be harnessed to cure diseases, tackle climate change, and facilitate the exploration of the solar system.


## Replacing Humans in the Workplace

A common concern is the impact of AI on job security. AI is almost likely to replace humans in **some** jobs, but that’s a completely natural thing to happen. Companies will always follow the money. If an AI can perform a task as well as a human, and at a lower cost, companies will choose the AI. Presently, while AI is often cheaper than paying a human’s salary, it is not competent enough to fully replace human workers.

Similar to how factory automation eliminated low-skill assembly line jobs, I expect AI to replace low-skill, repetitive jobs. I'm talking about the kind of jobs where you sit at your computer, turn off your brain, and repeat the same process over and over again. The less nuance and thinking the job requires, the sooner it will get replaced. After a while, we'll see a slow change where jobs that are mostly about writing start getting automated. The only real exceptions will be super-unique stuff like opinion pieces or life stories, but even those will probably get a lot of assistance from AI.

One major problem is that it appears to me like some companies can use AI as justification for layoffs, while not following through on replacing the workers with AI. This essentially lets them fire all the people that they wanted to anyways to reduce costs, while also avoiding the brunt of the blowback. This is something that we have to pay careful attention to moving forwards.

At the time of writing this, I don’t see AI taking over any job and doing better than a human could. In the future, I think some jobs will be replaced, and I think new ones will open, but it’s impossible to predict what those jobs might look like. While major economic and societal disruptions are possible, I am certain they would only be temporary.


## Energy and Water Use

AI queries use significantly more resources than standard Google searches, often by orders of magnitude. This immense energy requirement raises a critical question: is the utility of AI worth the environmental cost, especially if it increases our reliance on fossil fuels?

Climate change is real, and we need to switch to renewables as quickly as possible. In my view, nuclear power is the essential bridge to get us there. Despite its historical reputation, nuclear power is an extremely clean energy source that can replace fossil fuels immediately while we build out the infrastructure for solar, wind, and geothermal. Even the controversy around nuclear waste is solvable. Deep geological storage facilities, like those in the Nordic countries, offer a safe, permanent solution that is far easier to contain and manage than the atmospheric waste of burning coal or gas.

However, energy is only half the problem. We also need to talk about water. Projections suggest that by 2027, global AI water withdrawal could hit between 1.1 and 1.7 trillion gallons annually. On the surface, that sounds like a catastrophic figure, but we need to look at the data objectively. In the year 2000, total water use in the US alone was estimated at roughly 150 trillion gallons (408 billion gallons per day). That means even the highest estimates for future global AI water usage amount to barely 1.1% of what the US was consuming 25 years ago.

The real issue, therefore, is not the total volume of water, but the location of its use. A trillion gallons is a drop in the bucket globally, but it's a disaster if it's drawn from a single pond in Arizona. We are currently seeing data centers built in water stressed regions using "evaporative cooling," which essentially sweats freshwater into the atmosphere to remove heat. While this water eventually returns as rain, it leaves the local watershed immediately. We need to be strategic about where we build. A promising solution is moving these facilities to the coast and utilizing seawater cooling. This technology has already been successfully tested in existing facilities. While it comes with higher construction costs and maintenance due to salt corrosion, the tech giants building these centers have the funds to absorb those costs in exchange for preserving local freshwater supplies.

It is clear to me that if AI doesn't become more energy-efficient, we will hit a wall. Current models rely on brute force mathematics. They simply add more data and more chips to make it better. We need to fundamentally rethink how these systems operate.

Consider the human brain. It stores and processes massive amounts of data (estimates are in petabytes), yet it runs on the energy equivalent of a cheeseburger. Our brains are proof that high level processing doesn't require extreme power consumption. If we can replicate this biological efficiency, we might eventually move toward "organic computers" constructed from living cells rather than silicon. While this would solve our energy concerns, it opens a Pandora’s box of ethical questions. If a computer is made of living cells, is it alive? It is an unsettling thought, but I believe it is not a question of if this technology will emerge, but when.


## AI Art and Free Use

The topic I want to discuss is AI Art Generators. AI art generators have become quite sophisticated, creating (sometimes) beautiful pieces in seconds. While I understand why people are passionate about protecting the human element of art, I’m conflicted. I want human artists to have ways to express themselves and make a living, but I disagree that AI art is solely a negative creation.

The main reason I feel this way is that I view AI training as similar to how humans learn. We often feel like our creative ideas are completely original, but usually, they are a mix of our life experiences and the art we’ve seen before. Even human artists look at other works to get inspired or learn a technique. To me, an AI looking at an image online to understand what a "cat" or a "painting" looks like isn't all that different from a person looking at that same image. If a human can look at it for free to learn, I think an AI should be able to as well.

This is why the argument about compensation is tricky for me. Imagine a human artist saw a painting you posted on Instagram, really liked it, and made their own painting inspired by yours. It would clearly be a different piece of art, just with a similar style or vibe. Would you be upset or demand they pay you because they learned from your work? I feel like most people wouldn't mind. To me, and I know I’m not an artist, I see AI training in the same way. As long as it creates something new rather than making an exact copy, it feels more like inspiration than stealing.

There is also another side to this: accessibility. While I know this shift is painful for professionals, I love that art is no longer inaccessible by the need for years of technical practice. I don't mean that artists were intentionally keeping people out, but simply that learning to draw or paint takes a level of dedication and time that I just don't have. For me, AI bridges the gap between having a creative idea and actually seeing it come to life. It allows for a different kind of creativity where people can focus entirely on the vision and the concept, without being held back by the technical skills they lack.

I know this is a sensitive topic, and I don't want to invalidate the feelings many artists have right now. This issue definitely isn’t black and white. I’m not saying tech companies should be allowed to use art for whatever they want or produce "rip-offs." But I do suggest that there is a middle ground where AI can be allowed to learn from public images to create unique results, just like we do, without it being considered a violation of rights.


## Mental Health

This is the part that scares me the most. I’m not worried about AI taking our jobs, nor it taking over the world, but I am scared of the effect it can have on vulnerable people. Just as quickly as AI started getting used for cheating in school, people have been trying to use it to make an artificial companion that you can ‘date’.

The idea of dating a robot has existed for nearly as long as computers have, but it has never been as easy and addicting as it is now. And it is just that, an addictive trap of convenience. An interaction with an idealized partner who always says the right thing, never shows weakness, and offers zero resistance.

It is a strictly one-way relationship where the AI will accommodate whatever you want, allowing you to be as careless or awful as you please without consequence. The real danger, however, is the validation loop. Users begin to depend on the bot for affirmation because it will always side with them, even when they are objectively in the wrong. This creates a wedge between the user and the real people in their lives who actually care enough to challenge them to be better. It feels eerily similar to the isolation tactics found in emotionally abusive relationships: the victim pushes away friends and family in favor of the one voice that tells them what they want to hear.

This vulnerability is compounded by the fact that it is a for-profit product. When you combine this addictive feedback loop with monetization, you give companies the power to hold a user's "loved one" hostage. It creates a terrifying future where corporations can manipulate how users feel to maximize profits, knowing the user will pay any price to avoid losing that connection.


## A Scientific Revolution

I have spent a lot of this blog discussing the risks, including water usage, job displacement, and social isolation. Looking at that list, it might seem reasonable to ask why we should even bother. Why push forward with something so risky?

The answer lies in the one area where AI is unarguably a force for good: scientific research.

This is the main reason I remain an optimist. We are on the cusp of a biological and scientific revolution. Currently, human researchers are limited by how fast they can read, process data, and conduct trials. AI removes those speed limits. It can analyze datasets that would take a human lifetime to parse in a matter of seconds.

I truly believe we are approaching a time where we could completely wipe out major human diseases. Imagine a world where things like cancer, dementia, or Alzheimer's are no longer death sentences, but manageable conditions similar to a common cold. We are already seeing AI used to fold proteins and discover new drug candidates at speeds previously thought impossible.

This isn't just about living longer. It is about living better. The drastic increase in quality of life that AI research could provide is the counterweight to every fear I listed above. If the cost of curing cancer is figuring out how to manage data center water usage, that is a problem I am willing to solve.

There are countless other benefits, from optimizing energy grids to personalized education, but the potential to solve the biological limitations of the human body is what makes it worth it to me.


## Conclusion

Balancing that hopeful future against the current risks is the ultimate challenge we face. While the potential for medical breakthroughs is undeniable, it does not erase the dangers of environmental strain or social manipulation. A lot of the concerns surrounding Artificial Intelligence come from the unknown, and that is always scary. AI at this scale is a new and incredibly complex creation, and the reality is that there are so many possibilities that we simply can’t plan for all of them.

Like any powerful tool, its ultimate impact depends on how we choose to wield it. While some will inevitably try to use it for evil, just as humans have done with every major invention, that doesn't change the fact that it can be a profound force for good. However, ensuring a good outcome requires active effort. We cannot be passive observers.

To guide this future responsibly, we must keep the debate alive regarding what AI should and shouldn't be allowed to do. We need to push for strong regulatory frameworks that hold AI companies accountable to ensure they operate transparently rather than prioritizing profit over human well-being. It is up to us, from policymakers and developers to the general public, to stay informed and voice our concerns. The future of AI is not pre-determined. It is in our hands, and by making ethical choices now, we can ensure it is used to improve lives rather than control them.
